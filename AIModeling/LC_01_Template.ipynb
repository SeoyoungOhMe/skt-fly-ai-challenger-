{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMC3LtXR+I8nEZyYD2pGOI5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SeoyoungOhMe/skt-fly-ai-challenger-class/blob/master/LC_01_Template.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "flL2gMRAFbxL",
        "outputId": "706f965b-dc10-45e9-e6e3-2c213df5c30b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.10.0-py3-none-any.whl (225 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.1/225.1 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.26.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.10.14)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Collecting typing-extensions<5,>=4.7 (from openai)\n",
            "  Downloading typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: typing-extensions, h11, httpcore, httpx, openai\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.5.0\n",
            "    Uninstalling typing_extensions-4.5.0:\n",
            "      Successfully uninstalled typing_extensions-4.5.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed h11-0.14.0 httpcore-1.0.2 httpx-0.26.0 openai-1.10.0 typing-extensions-4.9.0\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.1.4-py3-none-any.whl (803 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m803.6/803.6 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.24)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.1)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.6.3-py3-none-any.whl (28 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langchain-community<0.1,>=0.0.14 (from langchain)\n",
            "  Downloading langchain_community-0.0.16-py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core<0.2,>=0.1.16 (from langchain)\n",
            "  Downloading langchain_core-0.1.17-py3-none-any.whl (235 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.9/235.9 kB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langsmith<0.1,>=0.0.83 (from langchain)\n",
            "  Downloading langsmith-0.0.85-py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.23.5)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.14)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.20.2-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.16->langchain) (3.7.1)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.16->langchain) (23.2)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2023.11.17)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.16->langchain) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.16->langchain) (1.2.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, jsonpointer, typing-inspect, langsmith, jsonpatch, langchain-core, dataclasses-json, langchain-community, langchain\n",
            "Successfully installed dataclasses-json-0.6.3 jsonpatch-1.33 jsonpointer-2.4 langchain-0.1.4 langchain-community-0.0.16 langchain-core-0.1.17 langsmith-0.0.85 marshmallow-3.20.2 mypy-extensions-1.0.0 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install openai\n",
        "!pip install langchain"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate, ChatPromptTemplate\n",
        "\n",
        "string_prompt = PromptTemplate.from_template('Tell me a joke about {subject}')\n",
        "string_prompt_value = string_prompt.format_prompt(subject='soccer')\n",
        "\n",
        "string_prompt_value.text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "0qzPTLEfFv-a",
        "outputId": "102eed06-0d11-4727-ec13-a09475821d66"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tell me a joke about soccer'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat_prompt = ChatPromptTemplate.from_template('Tell me a joke about {subject}')\n",
        "chat_prompt_value = chat_prompt.format_prompt(subject='soccer')\n",
        "\n",
        "chat_prompt_value.messages[0].content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "BCSCCUyHFv70",
        "outputId": "672fd68c-1564-4d3e-b9b7-7e58250565fc"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tell me a joke about soccer'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "template = '''\n",
        "  너는 요리사다. 내가 가진 재료들을 가지고 만들 수 있는 요리를 추천하고 그 요리의 레시피를 제시해라\n",
        "  내가 가진 재료는 아래와 같다.\n",
        "  <재료>\n",
        "  {재료}\n",
        "'''"
      ],
      "metadata": {
        "id": "3l6Lz0bRFv4U"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template = PromptTemplate(\n",
        "    input_variables = ['재료'],\n",
        "    template = template\n",
        ")\n",
        "\n",
        "prompt_template"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eX284QTrFvts",
        "outputId": "03558764-6a52-48b0-9957-edc8bf0ccbcf"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PromptTemplate(input_variables=['재료'], template='\\n  너는 요리사다. 내가 가진 재료들을 가지고 만들 수 있는 요리를 추천하고 그 요리의 레시피를 제시해라\\n  내가 가진 재료는 아래와 같다.\\n  <재료>\\n  {재료}\\n')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = prompt_template.format(재료='양파, 계란, 사과, 빵')"
      ],
      "metadata": {
        "id": "1E_alUawQlkG"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = '8c91c5c7058847f3820f9d7c12bbb1fb'\n",
        "os.environ['AZURE_OPENAI_ENDPOINT'] = 'https://sktfly-ai.openai.azure.com/'\n",
        "os.environ['OPENAI_API_TYPE'] = 'azure'\n",
        "os.environ['OPENAI_API_VERSION'] = '2023-05-15'"
      ],
      "metadata": {
        "id": "L9tk35PLFvYn"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import AzureOpenAI\n",
        "from langchain.chat_models import AzureChatOpenAI"
      ],
      "metadata": {
        "id": "sDY1r-F7FvWQ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = AzureOpenAI(\n",
        "    deployment_name = 'dev-gpt-35-turbo-instruct',\n",
        "    max_tokens = 1000\n",
        ")"
      ],
      "metadata": {
        "id": "VZ49toStFvT9"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm(prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "SR6NchgJFvRm",
        "outputId": "2c4cc9fb-22d3-4f9d-c315-1a46d6e6da35"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n  양파는 계란볶음밥으로 만들 수 있습니다.\\n  계란은 계란말이로 만들 수 있습니다.\\n  사과는 사과파이로 만들 수 있습니다.\\n  빵은 토스트로 만들 수 있습니다.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import(\n",
        "    ChatPromptTemplate,\n",
        "    PromptTemplate,\n",
        "    SystemMessagePromptTemplate,\n",
        "    AIMessagePromptTemplate,\n",
        "    HumanMessagePromptTemplate\n",
        ")\n",
        "\n",
        "from langchain.schema import(\n",
        "    SystemMessage,\n",
        "    AIMessage,\n",
        "    HumanMessage\n",
        ")"
      ],
      "metadata": {
        "id": "xhULCnIUFvPR"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 템플릿의 완성\n",
        "system_template_prompt = SystemMessagePromptTemplate.from_template(template)\n",
        "\n",
        "# Human Template\n",
        "human_template = '{재료}'\n",
        "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
        "\n",
        "# Chat Template\n",
        "chat_prompt = ChatPromptTemplate.from_messages([system_template_prompt,\n",
        "                                                human_message_prompt])\n",
        "# prompt = chat_prompt.format_prompt(재료='양파, 계란, 사과, 빵').to_messages()\n",
        "prompt = chat_prompt.format_prompt(재료='명란젓, 토마토소스, 돼지고기, 국수').to_messages()\n",
        "prompt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uRVuSUqvFvM2",
        "outputId": "33992837-1df1-4908-a7c8-5860554202f3"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[SystemMessage(content='\\n  너는 요리사다. 내가 가진 재료들을 가지고 만들 수 있는 요리를 추천하고 그 요리의 레시피를 제시해라\\n  내가 가진 재료는 아래와 같다.\\n  <재료>\\n  명란젓, 토마토소스, 돼지고기, 국수\\n'),\n",
              " HumanMessage(content='명란젓, 토마토소스, 돼지고기, 국수')]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chatgpt = AzureChatOpenAI(deployment_name='dev-gpt-35-turbo')\n",
        "answer = chatgpt(prompt)\n",
        "\n",
        "print(answer.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJUeZnCCFvKd",
        "outputId": "058400e8-94b8-466e-de41-6610708b6cf2"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "가지고 계신 재료로 \"명란젓 크림 파스타\"를 만들어 보시는 건 어떠신가요? 아래는 레시피입니다.\n",
            "\n",
            "[명란젓 크림 파스타 레시피]\n",
            "재료:\n",
            "- 국수\n",
            "- 돼지고기 (혹은 다른 육류)\n",
            "- 토마토소스\n",
            "- 명란젓\n",
            "- 식물성 크림 또는 우유\n",
            "- 마늘\n",
            "- 양파\n",
            "- 올리브 오일\n",
            "- 소금, 후추\n",
            "- 파슬리 (장식용)\n",
            "\n",
            "요리과정:\n",
            "1. 물을 끓여 국수를 삶습니다. 삶은 후 찬물에 헹궈 식힙니다.\n",
            "2. 팬에 올리브 오일을 두르고 다진 마늘과 양파를 볶습니다.\n",
            "3. 돼지고기를 넣고 볶은 후 토마토소스를 넣어 볶습니다.\n",
            "4. 명란젓을 조금 넣어 양념을 줍니다.\n",
            "5. 크림 또는 우유를 넣고 약한 불에서 졸입니다. 끓이는 동안 소금과 후추로 간을 합니다.\n",
            "6. 삶은 국수를 크림 소스에 넣고 섞어줍니다.\n",
            "7. 그릇에盛하여 파슬리를 곁들여 완성합니다.\n",
            "\n",
            "이렇게 하면 맛있는 명란젓 크림 파스타가 완성됩니다. 맛있게 드세요!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Few-shot learning template\n",
        "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "examples = [\n",
        "    {\n",
        "        'question' : '아이유로 삼행시를 지어줘',\n",
        "        'answer' : '''\n",
        "          아 아이유는\n",
        "          이 이상하고\n",
        "          유 유난히 좋다.\n",
        "        '''\n",
        "    },\n",
        "    {\n",
        "        'question' : '이순신으로 삼행시를 지어줘',\n",
        "        'answer' : '''\n",
        "          이 이순신 장군은\n",
        "          순 순순히 내어줄 것 같았던 조선의 바다를\n",
        "          신 신의와 충의의 마음으로 지켜냈다.\n",
        "        '''\n",
        "    }\n",
        "]"
      ],
      "metadata": {
        "id": "Wu1pgwWrFvIN"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_prompt = PromptTemplate(input_variables=['question', 'answer'],\n",
        "                                template='Question: {question}\\n{answer}')\n",
        "\n",
        "print(example_prompt.format(**examples[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQuIkPD3FvFt",
        "outputId": "8f92c828-e60c-4eca-b624-1f9a07e43fe7"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: 아이유로 삼행시를 지어줘\n",
            "\n",
            "          아 아이유는\n",
            "          이 이상하고\n",
            "          유 유난히 좋다.\n",
            "        \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = FewShotPromptTemplate(\n",
        "          examples=examples,\n",
        "          example_prompt= example_prompt,\n",
        "          suffix='Question:{input}',\n",
        "          input_variables=['input']\n",
        ")"
      ],
      "metadata": {
        "id": "jTpRZ6nHZsP0"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm.invoke('호날두로 삼행시를 지어줘 ')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "xBaM-0gtZsGO",
        "outputId": "1733d647-1991-45ba-def9-546224521c63"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\n오늘은 날씨가 좋다\\n외출하기 딱 좋은 날\\n사람들이 구경하며\\n호날두를 매우 좋아한다'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm(prompt.format(input='호날두로 삼행시를 지어줘'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "9fo95W1JZsD9",
        "outputId": "9a5869de-c9d6-4200-d919-0d52d5fafb9f"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\n          호 호날두는\\n          날 날렵하게 골을 넣고\\n          두 두려움 없이 세계를 지배한다.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm.invoke('뉴진스로 삼행시를 지어줘 ')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "DNhwNQzJZsBo",
        "outputId": "cac8f362-6d90-4c4b-bfdd-9bac2a87fa98"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\n나는 삼행시를 지어주는 뉴진스\\n창의적인 능력으로 도와준다\\n문장 하나 하나가 다른 매력을 띤다'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm(prompt.format(input='뉴진스로 삼행시를 지어줘'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "xpcanO9NZr_I",
        "outputId": "2b8c6e5d-4dbd-4b7f-9a0e-9d5ec10263b5"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\n          뉴 뉴스가 뜨거운\\n          진 진실을 갖춘다면\\n          스 승리는 더 가까워진다.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cO93h4_ibpll"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}